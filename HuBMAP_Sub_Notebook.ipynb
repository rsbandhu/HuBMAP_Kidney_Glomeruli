{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle, num_workers, split_ratio):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.N_tot = len(dataset)\n",
    "        self.train_samples = len(dataset)\n",
    "        self.train_sampler, self.val_sampler = self._split_sampler(split_ratio)\n",
    "\n",
    "        self.init_kawrgs = {\n",
    "            'dataset':dataset, 'batch_size':batch_size, 'shuffle':self.shuffle,\n",
    "            'num_workers':num_workers\n",
    "        }\n",
    "        super().__init__(sampler=self.train_sampler, **self.init_kawrgs)\n",
    "\n",
    "    def _split_sampler(self, split_ratio):\n",
    "        if split_ratio == 0:\n",
    "            return None, None\n",
    "        \n",
    "        idx_full = np.arange(self.N_tot)\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(idx_full)\n",
    "\n",
    "        if isinstance(split_ratio, int):\n",
    "            assert split_ratio > 0\n",
    "            assert split_ratio < self.N_tot, \n",
    "            val_len = split_ratio\n",
    "        else:\n",
    "            val_len = int(split_ratio*self.N_tot)\n",
    "\n",
    "        val_idx = idx_full[:val_len]\n",
    "        train_idx = np.delete(idx_full, np.arange(0, val_len))\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "        self.train_samples = self.N_tot - val_len\n",
    "\n",
    "        return train_sampler, val_sampler\n",
    "\n",
    "    def val_split(self):\n",
    "        if self.val_sampler is None:\n",
    "            return None\n",
    "        else:\n",
    "            return DataLoader(sampler=self.val_sampler, **self.init_kawrgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def mask_rle_to_2d(rle_mask, dx, dy):\n",
    "    \"\"\"\n",
    "    converts mask from run length encoding to 2D numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros(dx*dy, dtype=np.uint8)\n",
    "    s = rle_mask.split()  # split the rle encoding\n",
    "\n",
    "    for i in range(len(s)//2):\n",
    "        start = int(s[2*i])-1\n",
    "        length = int(s[2*i+1])\n",
    "        mask[start:start+length] = 1\n",
    "\n",
    "    mask = mask.reshape(dy, dx).T\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_2d_to_rle(mask_2d):\n",
    "    \"\"\"\n",
    "    Takes a 2D mask of 0/1 and returns the run length encoded form\n",
    "    \"\"\"\n",
    "    mask = mask_2d.T.reshape(-1) #order by columns and flatten to 1D\n",
    "    mask_padded = np.pad(mask, 1) #pad zero on both sides\n",
    "    #find the start positions of the 1's\n",
    "    starts = np.where(mask_padded[:-1] == 1 & (mask_padded[1:] == 0))[0]\n",
    "    #find the end positions of 1's for each run\n",
    "    ends = np.where((mask_padded[:-1] == 0) & (mask_padded[1:] == 1))[0]\n",
    "    \n",
    "    rle = np.zeros(2*len(starts))\n",
    "    print(starts.shape, ends.shape, rle.shape)\n",
    "    rle[::2] = starts\n",
    "    #length of each run = end position - start position\n",
    "    rle[1::2] = ends - starts\n",
    "\n",
    "    return rle\n",
    "\n",
    "\n",
    "def get_padsize(img, reduce, sz):\n",
    "\n",
    "    shape = img.shape\n",
    "    print(shape)\n",
    "\n",
    "    pad0 = (reduce*sz - shape[0] % (reduce*sz)) % (reduce*sz)\n",
    "    pad1 = (reduce*sz - shape[1] % (reduce*sz)) % (reduce*sz)\n",
    "    pad_x = (pad0//2, pad0-pad0//2)\n",
    "    pad_y = (pad1//2, pad1-pad1//2)\n",
    "\n",
    "    return pad_x, pad_y\n",
    "\n",
    "\n",
    "def check_threshold(img_BGR, sat_threshold, pixcount_th):\n",
    "\n",
    "    \"\"\"\n",
    "    checks if an input image passes the threshold conditions:\n",
    "    conditions:\n",
    "    not black--> sum of pixels exceeed a threshold = pixcount_th\n",
    "    saturation --> number of pixels with saturation > sat_threshold exceeds pixcount_th\n",
    "    Returns:\n",
    "    True if both conditions are met else False\n",
    "    \"\"\"\n",
    "    #if most of the pixels are black, return False\n",
    "    #edge of each image is typically black\n",
    "    if img_BGR.sum() < pixcount_th:\n",
    "        return False\n",
    "\n",
    "    #convert to hue, saturation, Value in openCV\n",
    "    hsv = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    # if less than prefined number of values are above a saturation threshold, return False\n",
    "    #this is typically the gray background around the biological object\n",
    "    if (s > sat_threshold).sum() < pixcount_th:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def image_reshape(img):\n",
    "    '''\n",
    "    return the shape of an image in the format [x_shape, y_shape, color_channels]\n",
    "    some images have the shape [1,1,3,x,y]\n",
    "    change them to have the shape = [x,y,3]\n",
    "    reshape image accordingly\n",
    "    returns:\n",
    "    shape: new shape in the form [x,y,c]\n",
    "    reshaped image\n",
    "    '''\n",
    "    shape = img.shape\n",
    "\n",
    "    \n",
    "    if len(img.shape) == 5:\n",
    "        img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "        shape = img.shape\n",
    "\n",
    "    return shape, img\n",
    "\n",
    "\n",
    "def split_image_into_tiles(img, mask, reduce=4, sz=256):\n",
    "    \"\"\"\n",
    "    Takes an input image of shape [dx, dy,3]\n",
    "    pads it on all 4 sides by zeros so that final dx and dy are integral multiple of sz=256\n",
    "    Then reshapes the image into [-1, sz, sz, 3]\n",
    "    The first dimennsion is the number of images of size [sz, sz, 3] we get from the original image\n",
    "    Returns:\n",
    "    a numpy arr ay of shape [-1, sz, sz, 3]\n",
    "    \"\"\"\n",
    "\n",
    "    shape, img = image_reshape(img)\n",
    "    \n",
    "    pad0 = (reduce*sz - shape[0] % (reduce*sz)) % (reduce*sz)\n",
    "    pad1 = (reduce*sz - shape[1] % (reduce*sz)) % (reduce*sz)\n",
    "    pad_x = (pad0//2, pad0-pad0//2)\n",
    "    pad_y = (pad1//2, pad1-pad1//2)\n",
    "    img_padded = np.pad(img, [pad_x, pad_y, (0, 0)], constant_values=0)\n",
    "    print(\"shape of image after padding:: \",img_padded.shape, img_padded.shape[0]//sz, img_padded.shape[1]//sz)\n",
    "\n",
    "    mask_padded = np.pad(mask, [pad_x, pad_y], constant_values=0) #pad the 2D mask for the image\n",
    "    print(\"shape of mask padded \", mask_padded.shape)\n",
    "    #tile the padded image\n",
    "    img_reshaped = img_padded.reshape(\n",
    "        img_padded.shape[0]//sz, sz, img_padded.shape[1]//sz, sz, 3)\n",
    "    img_reshaped = img_reshaped.transpose(0, 2, 1, 3, 4).reshape(-1, sz, sz, 3)\n",
    "\n",
    "    #tile the padded mask\n",
    "    mask_tiled = mask_padded.reshape(\n",
    "        img_padded.shape[0]//sz, sz, img_padded.shape[1]//sz, sz)\n",
    "    mask_tiled = mask_tiled.transpose(0,2,1,3).reshape(-1, sz, sz) \n",
    "\n",
    "    print(f\"shape final tile: {img_reshaped.shape}, shape final mask: {mask_tiled.shape}, number of tiles and mask = {img_reshaped.shape[0]}, {mask_tiled.shape[0]}\")\n",
    "\n",
    "    return img_reshaped, mask_tiled\n",
    "\n",
    "\n",
    "def save_thresholded_image(img, mask, raw_img_name, sz, output_dir, mask_tile_dict, sat_threshold=40, pixcount_th=200):\n",
    "    n = img.shape[0]\n",
    "    valid_img_count = 0\n",
    "    sat_threshold = 40\n",
    "    pixcount_th = 200\n",
    "    valid_idx = []\n",
    "    print(f\"Original tiled image count = {n}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        img_BGR = img[i, :, :, :]\n",
    "        if check_threshold(img_BGR, sat_threshold, pixcount_th):\n",
    "            valid_img_count += 1\n",
    "            valid_idx.append(i)\n",
    "            #img_BGR = cv2.imencode('.png', img_BGR)[1]\n",
    "            #img_out.writestr(f'test_512_{i}.png', img_BGR)\n",
    "            #create an id for the image tile\n",
    "            img_tile_id = raw_img_name+'_'+str(sz)+'_'+str(valid_img_count)\n",
    "            img_name = img_tile_id+'.png' #name of the saved image tile\n",
    "\n",
    "            mask_for_tile = mask[i, :, :] #get the mask for the tile\n",
    "            #convert the mask for the tile to rle\n",
    "            mask_rle = mask_2d_to_rle(mask_for_tile)\n",
    "            #save the rle mask to a dict, key = name of the corresponding image tile\n",
    "            mask_tile_dict[img_tile_id]=mask_rle\n",
    "\n",
    "            #if valid_img_count == 1001:\n",
    "            cv2.imwrite(os.path.join(output_dir, img_name), img_BGR)\n",
    "    print(f\"Image count after thresholding = {valid_img_count}\")\n",
    "    \n",
    "    \n",
    "def image_transform(mode='train'):\n",
    "    transform = None\n",
    "\n",
    "    v_flip = transforms.RandomVerticalFlip()\n",
    "    h_flip = transforms.RandomHorizontalFlip()\n",
    "\n",
    "    if mode == 'train':\n",
    "        transform = transforms.Compose([v_flip, h_flip])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    datadir_train = '/media/bony/Ganga_HDD_3TB/Ganges_Backup/Machine_Learning/HuBMAP_Hacking_Kidney/hubmap-kidney-segmentation/train'\n",
    "    os.chdir(datadir_train)\n",
    "    masks_train = '/media/bony/Ganga_HDD_3TB/Ganges_Backup/Machine_Learning/HuBMAP_Hacking_Kidney/hubmap-kidney-segmentation/train.csv'\n",
    "    image_size = 512\n",
    "    output_dir = os.path.join(datadir_train, 'tiled_'+str(image_size))\n",
    "    #os.mkdir(output_dir)\n",
    "    print(output_dir)\n",
    "    raw_image_files = [f for f in os.listdir(datadir_train) if \"tiff\" in f]\n",
    "\n",
    "    df_train_masks = pd.read_csv(masks_train).set_index('id')\n",
    "    img_train_list = list(df_train_masks.index)\n",
    "    print(img_train_list)\n",
    "    #mask_rle = df_train_masks.loc['2f6ecfcdf', 'encoding']\n",
    "    mask_tile_dict = {}\n",
    "    \n",
    "    #loop over the original image files\n",
    "    #split each image file into multiple files\n",
    "    #discard the ones that have too many black pixels or uniform saturation\n",
    "    for f in raw_image_files:\n",
    "        raw_file_name = f.split('.')[0]\n",
    "        print(raw_file_name)\n",
    "\n",
    "        mask_rle = df_train_masks.loc[raw_file_name, 'encoding']\n",
    "        #print(raw_image_files)\n",
    "    \n",
    "        img_raw = tiff.imread(os.path.join(datadir_train, f))\n",
    "        [dx, dy, c], img_raw = image_reshape(img_raw)\n",
    "\n",
    "        #create the 2d mask from rle \n",
    "        mask_2d = mask_rle_to_2d(mask_rle, dx, dy)\n",
    "        print(\"shape of unpadded 2D mask \", mask_2d.shape)\n",
    "        #create an array of one more diemension for the different tiles\n",
    "        tiled_img , tiled_mask = split_image_into_tiles(img_raw, mask_2d, reduce=1, sz=image_size)\n",
    "\n",
    "        print(tiled_img.shape)\n",
    "        #save only those tiles that meet the saturation and black pixel count criteria\n",
    "        #save_thresholded_image(tiled_img, tiled_mask, raw_file_name, image_size, output_dir, mask_tile_dict)\n",
    "    #cv2.imwrite('test.png', tiled_img[1000,:,:,:])\n",
    "    #np.save(\"tiled_mask_dict.npy\", mask_tile_dict)\n",
    "    #print(raw_image_files[0])\n",
    "    #img_raw = tiff.imread(os.path.join(datadir_train, raw_image_files[0]))\n",
    "    #print(img_raw.shape)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os, sys\n",
    "import tifffile as tiff\n",
    "import zipfile\n",
    "import json\n",
    "import pickle\n",
    "import preprocessing_utils as utils\n",
    "import cv2\n",
    "\n",
    "\n",
    "class Image():\n",
    "    def __init__(self, img, img_name =None):\n",
    "        self.img = img\n",
    "        self.shape = img.shape\n",
    "        self.name = img_name\n",
    "\n",
    "        self.image_reshape()\n",
    "        self.dx = self.shape[0]\n",
    "        self.dy = self.shape[1]\n",
    "\n",
    "        self.tile_size = None\n",
    "\n",
    "        self.pad_x = None\n",
    "        self.pad_y = None\n",
    "        self.tiled_img = None\n",
    "\n",
    "        self.mask_rle = None\n",
    "        self.mask_2d = None\n",
    "        self.tiled_mask = None\n",
    "        \n",
    "    def image_reshape(self):\n",
    "    \n",
    "        if len(self.shape) == 5:\n",
    "            self.img = np.transpose(self.img.squeeze(), (1, 2, 0))\n",
    "            self.shape = self.img.shape\n",
    "            \n",
    "    \n",
    "    def split_image_mask_into_tiles(self, reduce=1, sz=512):\n",
    "     \n",
    "        self.tile_size = sz\n",
    "\n",
    "        self.pad_x, self.pad_y = utils.get_padsize(self.img, reduce, sz)\n",
    "        print(self.pad_x, self.pad_y)\n",
    "        #Create padded Image and padded mask2D\n",
    "        img_padded  = np.pad(self.img, [self.pad_x, self.pad_y, (0, 0)], constant_values=0)\n",
    "        mask_padded = np.pad(self.mask_2d, [self.pad_x, self.pad_y], constant_values = 0)\n",
    "\n",
    "        print(\"shape of image after padding:: \", img_padded.shape,\n",
    "            img_padded.shape[0]//sz, img_padded.shape[1]//sz)\n",
    "\n",
    "        print(\"shape of mask after padding:: \", mask_padded.shape,\n",
    "              mask_padded.shape[0]//sz, mask_padded.shape[1]//sz)\n",
    "\n",
    "        #tile the padded image\n",
    "        img_reshaped = img_padded.reshape(\n",
    "            img_padded.shape[0]//sz, sz, img_padded.shape[1]//sz, sz, 3)\n",
    "        img_reshaped = img_reshaped.transpose(0, 2, 1, 3, 4).reshape(-1, sz, sz, 3)\n",
    "\n",
    "        #tile the padded mask2D\n",
    "        mask_reshaped = mask_padded.reshape(\n",
    "            mask_padded.shape[0]//sz, sz, mask_padded.shape[1]//sz, sz)\n",
    "        mask_reshaped = mask_reshaped.transpose(\n",
    "            0, 2, 1, 3).reshape(-1, sz, sz)\n",
    "\n",
    "        self.tiled_img = img_reshaped\n",
    "        self.tiled_mask = mask_reshaped\n",
    "        \n",
    "    \n",
    "    def save_thresholded_image(self, tiled_threshold_img_dir, mask_tile_dict, sat_threshold=40, pixcount_th=200):\n",
    "        n = self.tiled_img.shape[0]\n",
    "\n",
    "        valid_img_count = 0\n",
    "        valid_idx = []\n",
    "        print(f\"Original tiled image count = {n}\")\n",
    "\n",
    "        for i in range(n):\n",
    "            img_BGR = self.tiled_img[i, :, :, :]\n",
    "            if utils.check_threshold(img_BGR, sat_threshold, pixcount_th):\n",
    "                valid_img_count += 1\n",
    "                valid_idx.append(i)\n",
    "                \n",
    "                #create an id for the image tile\n",
    "                img_tile_id = f\"{self.name}_{str(self.tile_size)}_{str(valid_img_count)}_{str(i)}\"\n",
    "                img_name = img_tile_id+'.png'  # name of the saved image tile\n",
    "\n",
    "                mask_for_tile = self.tiled_mask[i, :, :]  # get the mask for the tile\n",
    "                #convert the mask for the tile to rle\n",
    "                mask_rle = self.mask_2d_to_rle(mask_for_tile)\n",
    "                #save the rle mask to a dict, key = name of the corresponding image tile\n",
    "                mask_tile_dict[img_tile_id] = mask_rle\n",
    "\n",
    "                #if valid_img_count == 1001:\n",
    "                cv2.imwrite(os.path.join(tiled_threshold_img_dir, img_name), img_BGR)\n",
    "\n",
    "        print(f\"Image count after thresholding = {valid_img_count}\")\n",
    "\n",
    "\n",
    "    def mask_rle_to_2d(self):\n",
    "        \"\"\"\n",
    "        converts mask from run length encoding to 2D numpy array\n",
    "        \"\"\"\n",
    "        dx = self.dx\n",
    "        dy = self.dy\n",
    "\n",
    "    \n",
    "        mask = np.zeros(dx*dy, dtype=np.uint8)\n",
    "        s = self.mask_rle.split()  # split the rle encoding\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i])-1\n",
    "            length = int(s[2*i+1])\n",
    "            mask[start:start+length] = 1\n",
    "        self.mask_2d = mask.reshape(dy, dx).T\n",
    "        \n",
    "        self.mask_2d = utils.mask_rle_to_2d(self.mask_rle, dx, dy)\n",
    "        \n",
    "    \n",
    "    def mask_2d_to_rle(self, mask_2d):\n",
    "        \"\"\"\n",
    "        Takes a 2D mask of 0/1 and returns the run length encoded form\n",
    "        \"\"\"\n",
    "\n",
    "        mask = mask_2d.T.reshape(-1)  # order by columns and flatten to 1D\n",
    "        mask_padded = np.pad(mask, 1)  # pad zero on both sides\n",
    "        #find the start positions of the 1's\n",
    "        starts = np.where((mask_padded[:-1] == 0) & (mask_padded[1:] == 1))[0]\n",
    "        #find the end positions of 1's for each run\n",
    "        ends = np.where((mask_padded[:-1] == 1) & (mask_padded[1:] == 0))[0]\n",
    "\n",
    "        rle = np.zeros(2*len(starts))\n",
    "        \n",
    "        rle[::2] = starts\n",
    "        #length of each run = end position - start position\n",
    "        rle[1::2] = ends - starts\n",
    "        rle = rle.astype(int)\n",
    "        return rle\n",
    "    \n",
    "    def main():\n",
    "        #setting parameters for tiling and thresholding raw images\n",
    "        image_size_reduced = 512\n",
    "        sat_threshold=40\n",
    "        pixcount_th=200\n",
    "\n",
    "        #set the directories for input raw images and output tiled images\n",
    "        datadir_train = '/media/bony/Ganga_HDD_3TB/Ganges_Backup/Machine_Learning/HuBMAP_Hacking_Kidney/hubmap-kidney-segmentation/train'\n",
    "        masks_train = '/media/bony/Ganga_HDD_3TB/Ganges_Backup/Machine_Learning/HuBMAP_Hacking_Kidney/hubmap-kidney-segmentation/train.csv'\n",
    "        tiled_threshold_img_dir = os.path.join(datadir_train, 'tiled_thresholded_'+str(image_size_reduced))\n",
    "        if not os.path.exists(tiled_threshold_img_dir):\n",
    "            os.makedirs(tiled_threshold_img_dir)\n",
    "\n",
    "        #read the mask of the images in rle format\n",
    "        df_train_masks = pd.read_csv(masks_train).set_index('id')\n",
    "\n",
    "        #get a list of all the raw images\n",
    "        os.chdir(datadir_train)\n",
    "        raw_image_files = [f for f in os.listdir(datadir_train) if \"tiff\" in f]\n",
    "\n",
    "        mask_tile_dict = {}\n",
    "        \n",
    "    count = 0\n",
    "    for f in raw_image_files:\n",
    "        raw_file_name = f.split('.')[0]\n",
    "        print(raw_file_name)\n",
    "        \n",
    "        img_raw = tiff.imread(os.path.join(datadir_train, f))\n",
    "        raw_img = Image(img_raw, img_name = raw_file_name)\n",
    "        #get the mask for the image in rle format\n",
    "        raw_img.mask_rle = df_train_masks.loc[raw_file_name, 'encoding']\n",
    "\n",
    "        raw_img.mask_rle_to_2d() #convert mask from rle to 2D\n",
    "        #print(raw_img.mask_rle[:100])\n",
    "        #print(f\"shape of raw image: {raw_img.shape}, of mask 2D : {raw_img.mask_2d.shape}\")\n",
    "        #print(raw_img.__dir__())\n",
    "\n",
    "        raw_img.split_image_mask_into_tiles(sz=image_size_reduced)\n",
    "        print(f\"shape of tiled image: {raw_img.tiled_img.shape}, of tiled mask 2D : {raw_img.tiled_mask.shape}\")\n",
    "\n",
    "        raw_img.save_thresholded_image(tiled_threshold_img_dir, mask_tile_dict, sat_threshold=sat_threshold, pixcount_th=pixcount_th)\n",
    "        count += 1\n",
    "\n",
    "    #save the tiled mask dict into a file for later use\n",
    "\n",
    "    tiled_mask_rle_file = open(os.path.join(tiled_threshold_img_dir, 'tiled_mask_rle'), 'wb')\n",
    "    pickle.dump(mask_tile_dict, tiled_mask_rle_file)\n",
    "    tiled_mask_rle_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Inference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import torch \n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocessing_utils as utils\n",
    "\n",
    "\n",
    "class Dataset_Image_mask(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, mean, std_dev, transform=None):\n",
    "        super(Dataset_Image_mask, self).__init__()\n",
    "        self.root_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dict = self.get_mask_dict()\n",
    "        self.img_name_list = list(self.mask_dict.keys())\n",
    "        self.len = self.__len__()\n",
    "        self.normalize = transforms.Normalize(mean, std_dev)\n",
    "\n",
    "        \n",
    "\n",
    "    def get_mask_dict(self):\n",
    "        '''\n",
    "        open the pickled file containing the dict of mask in rle format\n",
    "        returns\n",
    "        dict: key same as imgae file name\n",
    "        value: numpy array in rle format\n",
    "        '''\n",
    "        img_and_mask_files = os.listdir(self.root_dir)\n",
    "        mask_rle_file = [x for x in img_and_mask_files if \"mask\" in x][0]\n",
    "        mask_rle_dict = pickle.load(\n",
    "            open(os.path.join(self.root_dir, mask_rle_file), 'rb'))\n",
    "        return mask_rle_dict\n",
    "\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.img_name_list)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_name_list[idx]\n",
    "        img_file_name = os.path.join(self.root_dir, f\"{img_name}.png\")\n",
    "        img = io.imread(img_file_name)\n",
    "        #img = torch.tensor(img.transpose((2,0,1))).float()\n",
    "        #img = img.transpose(2, 0, 1)\n",
    "        \n",
    "        mask_rle_np = self.mask_dict[img_name]\n",
    "        #print(\"mask rle shape :: \", mask_rle_np.shape)\n",
    "        #print(f\"**\\n{mask_rle_np}\")\n",
    "        mask_rle = \" \".join(str(x) for x in mask_rle_np)\n",
    "        \n",
    "        mask_2d = utils.mask_rle_to_2d(mask_rle, 512, 512)\n",
    "        #augment image for training\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            mask_2d = self.transform(mask_2d)\n",
    "        \n",
    "        img = self.normalize(transforms.ToTensor()(img))\n",
    "        mask = torch.from_numpy(mask_2d).long()\n",
    "\n",
    "        sample = {'image': img, 'mask': mask, 'idx': img_name}\n",
    "        #sample = {'image': img}\n",
    "        return sample\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_dir = '/media/bony/Ganga_HDD_3TB/Ganges_Backup/Machine_Learning/HuBMAP_Hacking_Kidney/hubmap-kidney-segmentation/train/tiled_thresholded_512'\n",
    "    mean = [0.68912, 0.47454, 0.6486]\n",
    "    std_dev = [0.13275, 0.23647, 0.15536]\n",
    "\n",
    "\n",
    "    dataset = Dataset_Image_mask(data_dir, mean, std_dev)\n",
    "    n_tot = dataset.len\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    train_count = int(train_test_split * n_tot)\n",
    "\n",
    "    test_count = dataset.len - train_count\n",
    "\n",
    "    train_idx = list(np.random.choice(range(n_tot), train_count, replace = False))\n",
    "    test_idx = list(set(range(n_tot)) - set(train_idx))\n",
    "\n",
    "    print(len(train_idx), len(test_idx), n_tot - len(train_idx) - len(test_idx))\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(dataset, train_idx)\n",
    "    test_ds = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "    train_loader = DataLoader(train_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size= 4, shuffle= True, num_workers= 0)\n",
    "    \n",
    "    for i, sample_batch in enumerate(test_loader):\n",
    "        print(i, sample_batch['image'].shape, sample_batch['mask'].shape)\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    for i in range(30):\n",
    "        sample = dataset[i]\n",
    "        print(sample['image'].shape)\n",
    "        if i == 83:\n",
    "            img = sample['image']\n",
    "            plt.imshow(img)\n",
    "    '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.base_trainer import BaseTrainer\n",
    "from utils import dataloader, loss, metrics\n",
    "from models import unet\n",
    "\n",
    "class Trainer(BaseTrainer):\n",
    "\n",
    "    def __init__(self, model, loss_fn, config, train_loader, val_loader=None):\n",
    "        super(Trainer, self).__init__(\n",
    "            model, loss_fn, config, train_loader, val_loader)\n",
    "\n",
    "        self.optimizer = loss.use_optimizer(model, config)\n",
    "        self.bce_dice_ratio = config['loss'][\"bce_dice_ratio\"]\n",
    "\n",
    "    def _train_epoch(self, epoch):\n",
    "        '''\n",
    "        train the model for one epoch\n",
    "        '''\n",
    "        self.model.train()\n",
    "        self._reset_metrics()\n",
    "        tbar = tqdm(self.train_loader, ncols = 100, miniters=50)\n",
    "\n",
    "        for i, sample_batch in enumerate(tbar):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            img = sample_batch['image']\n",
    "            mask = sample_batch['mask'].float()\n",
    "\n",
    "            batch_size = img.shape[0]\n",
    "\n",
    "            img = img.to(self.device)\n",
    "            mask = mask.to(self.device)\n",
    "            #img = img.transpose((0,3,1,2))\n",
    "            out = torch.squeeze(self.model(img), 1)\n",
    "            \n",
    "            train_loss = self.loss(out, mask, self.bce_dice_ratio)\n",
    "            self.total_loss.update(train_loss.item(), batch_size)\n",
    "\n",
    "            train_loss.backward() #perform backprop\n",
    "            self.optimizer.step() #update parameters\n",
    "\n",
    "            tbar.set_description( f\"Train: Epoch: {epoch}, Avg Loss: {self.total_loss.avg:.5f}\" )\n",
    "            #if (i % 50 == 0):\n",
    "            #    print(f\"epoch: {epoch}, batch : {i}, train loss: {train_loss.item(): .5f}, train average loss: {self.total_loss.avg: .5f}\")\n",
    "            #    break\n",
    "        return self.total_loss.avg\n",
    "\n",
    "    \n",
    "    def _val_epoch(self, epoch):\n",
    "        if self.val_loader is None:\n",
    "            print(f\"No val loader exists\")\n",
    "            return {}\n",
    "\n",
    "        self.model.eval()\n",
    "        self._reset_metrics()\n",
    "        tbar = tqdm(self.val_loader, ncols=100)\n",
    "        with torch.no_grad():\n",
    "            for i, sample_batch in enumerate(tbar):\n",
    "                img = sample_batch['image']\n",
    "                mask = sample_batch['mask'].float()\n",
    "\n",
    "                batch_size = img.shape[0]\n",
    "                img = img.to(self.device)\n",
    "                mask = mask.to(self.device)\n",
    "\n",
    "                out = torch.squeeze(self.model(img), 1)\n",
    "                val_loss = self.loss(out, mask, self.bce_dice_ratio)\n",
    "                self.total_loss.update(val_loss.item(), batch_size)\n",
    "                #if (i%10 == 0):\n",
    "                #    print(f\"epoch: {epoch}, batch : {i}, val loss: {val_loss.item()}, val average loss: {self.total_loss.avg}\")\n",
    "                tbar.set_description(f\"Val: Epoch: {epoch}, Avg Loss: {self.total_loss.avg:.5f}\")\n",
    "\n",
    "        return self.total_loss.avg\n",
    "    \n",
    "    \n",
    "    def _reset_metrics(self):\n",
    "\n",
    "        self.total_loss = metrics.AverageMeter()\n",
    "        \n",
    "        \n",
    "    def main():\n",
    "        root_dir = 'C:\\Scripts\\hubmap\\code'\n",
    "\n",
    "        data_dir = 'C:\\Scripts\\hubmap\\\\train\\\\tiled_thresholded_512'\n",
    "\n",
    "        mean = [0.68912, 0.47454, 0.6486]\n",
    "        std_dev = [0.13275, 0.23647, 0.15536]\n",
    "\n",
    "        #full dataset with training images and masks\n",
    "        dataset = dataloader.Dataset_Image_mask(data_dir, mean, std_dev)\n",
    "\n",
    "        n_tot = dataset.len\n",
    "\n",
    "        #SplitS full dataset into train set and test set\n",
    "        train_test_split = 0.8\n",
    "        train_count = int(train_test_split * n_tot)\n",
    "\n",
    "        test_count = dataset.len - train_count\n",
    "\n",
    "        train_idx = list(np.random.choice(\n",
    "            range(n_tot), train_count, replace=False))\n",
    "        test_idx = list(set(range(n_tot)) - set(train_idx))\n",
    "\n",
    "        print(len(train_idx), len(test_idx), n_tot - len(train_idx) - len(test_idx))\n",
    "\n",
    "        train_ds = torch.utils.data.Subset(dataset, train_idx)\n",
    "        test_ds = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "        model = unet.UNet()\n",
    "\n",
    "        config = json.load(open('config.json'))\n",
    "        b_size = config[\"train_loader\"][\"args\"][\"batch_size\"]\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, batch_size=b_size, shuffle=True, num_workers=0)\n",
    "        b_size = config[\"val_loader\"][\"args\"][\"batch_size\"]\n",
    "        val_loader = DataLoader(\n",
    "            test_ds, batch_size=b_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        trainer = Trainer(model, loss.loss_fn, config, train_loader, val_loader)\n",
    "        print(f\"Trainining on device: {trainer.device}\")\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
